# OpenAI-compatible API (LiteLLM proxy)
# The backend uses OPENAI_* prefix for compatibility with OpenAI SDKs
OPENAI_BASE_URL=http://localhost:4000
OPENAI_API_KEY=your_api_key_here

# Default models (optional - config.json has defaults)
# Override these to change the default model for each task
VISION_MODEL=gpt-4o
DESCRIPTION_MODEL=gemini-3-flash-preview
IMAGE_GEN_MODEL=gemini-3-pro-image-preview
VIDEO_GEN_MODEL=veo-3.1-generate-001

# Image provider selection: "litellm" or "nvidia"
# - litellm: Use LiteLLM proxy for image generation
# - nvidia: Use NVIDIA NIM API directly (requires NVIDIA_API_KEY)
IMAGE_PROVIDER=litellm

# NVIDIA Direct API (only needed if IMAGE_PROVIDER=nvidia)
# Supports Stable Diffusion 3/3.5 and FLUX.1 models
NVIDIA_API_KEY=your_nvidia_api_key_here
NVIDIA_IMAGE_GEN_URL=https://ai.api.nvidia.com/v1/genai/stabilityai/stable-diffusion-3-medium

# Application settings
LOG_LEVEL=INFO
